# Emotion understanding via multimodality context-aware micro gesture recognition


<div align="center">
    <img src="https://lut.pictures.fi/kuvat/LUT%20Press%20Images/LOGOS/LUT%20Logo/Logo%20for%20print/LUT%20logo%20%7C%20full%20black%20CMYK%20pdf.pdf?img=img2048" width="40%">
</div>

# Dependency

LineCounter is written in Pytorch.
  
  - Pytorch-GPU: 2.0.1
  
Other versions might also work but are not tested.


# Demo

Download the repo and create the virtual environment by following commands

```
conda create --name Visual-Text-MG --file spec-env.txt
conda activate Visual-Text-MG
pip3 install torch torchvision torchaudio
pip install opencv-python
```

Then play with the provided ipython notebook.

# Datasets
We do not own the copyright of the dataset used in this repo.

Below is a summary table of the datasets used in this work along with a link from which they can be downloaded:


| Dataset      | URL     |
| ------------ | ------- |
| SMG  | https://github.com/mikecheninoulu/SMG  |
| DIBCO 2010   | https://github.com/linuxsino/iMiGUE |

# Concat

For any paper-related questions, please feel free to contact leedengsh@gmail.com.
